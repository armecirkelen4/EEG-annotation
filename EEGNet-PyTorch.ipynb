{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by, \n",
    "Sriram Ravindran, sriram@ucsd.edu\n",
    "\n",
    "Original paper - https://arxiv.org/abs/1611.08024\n",
    "\n",
    "Please reach out to me if you spot an error.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>762870</th>\n",
       "      <th>762871</th>\n",
       "      <th>762872</th>\n",
       "      <th>762873</th>\n",
       "      <th>762874</th>\n",
       "      <th>762875</th>\n",
       "      <th>762876</th>\n",
       "      <th>762877</th>\n",
       "      <th>762878</th>\n",
       "      <th>762879</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>channel_1</th>\n",
       "      <td>1.412883e+07</td>\n",
       "      <td>1.410380e+07</td>\n",
       "      <td>1.410851e+07</td>\n",
       "      <td>1.411343e+07</td>\n",
       "      <td>-4.909065e+06</td>\n",
       "      <td>-4.948905e+06</td>\n",
       "      <td>-4.949609e+06</td>\n",
       "      <td>-4.952393e+06</td>\n",
       "      <td>3.253510e+06</td>\n",
       "      <td>3.231366e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.643658e+06</td>\n",
       "      <td>-5.641706e+06</td>\n",
       "      <td>-3.462086e+06</td>\n",
       "      <td>-3.462502e+06</td>\n",
       "      <td>-3.461254e+06</td>\n",
       "      <td>-3.461862e+06</td>\n",
       "      <td>-5.158634e+06</td>\n",
       "      <td>-5.159946e+06</td>\n",
       "      <td>-5.155018e+06</td>\n",
       "      <td>-5.154762e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_34</th>\n",
       "      <td>1.411228e+07</td>\n",
       "      <td>1.410508e+07</td>\n",
       "      <td>1.411683e+07</td>\n",
       "      <td>1.411913e+07</td>\n",
       "      <td>-4.927497e+06</td>\n",
       "      <td>-4.954985e+06</td>\n",
       "      <td>-4.941001e+06</td>\n",
       "      <td>-4.947593e+06</td>\n",
       "      <td>3.241126e+06</td>\n",
       "      <td>3.229286e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.643402e+06</td>\n",
       "      <td>-5.647914e+06</td>\n",
       "      <td>-3.457190e+06</td>\n",
       "      <td>-3.457830e+06</td>\n",
       "      <td>-3.459910e+06</td>\n",
       "      <td>-3.461766e+06</td>\n",
       "      <td>-5.158218e+06</td>\n",
       "      <td>-5.154698e+06</td>\n",
       "      <td>-5.154378e+06</td>\n",
       "      <td>-5.156010e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_5</th>\n",
       "      <td>1.412431e+07</td>\n",
       "      <td>1.408847e+07</td>\n",
       "      <td>1.411033e+07</td>\n",
       "      <td>1.411014e+07</td>\n",
       "      <td>-4.917001e+06</td>\n",
       "      <td>-4.967753e+06</td>\n",
       "      <td>-4.954601e+06</td>\n",
       "      <td>-4.961673e+06</td>\n",
       "      <td>3.247974e+06</td>\n",
       "      <td>3.218182e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.644170e+06</td>\n",
       "      <td>-5.642218e+06</td>\n",
       "      <td>-3.459174e+06</td>\n",
       "      <td>-3.458790e+06</td>\n",
       "      <td>-3.462886e+06</td>\n",
       "      <td>-3.461894e+06</td>\n",
       "      <td>-5.157930e+06</td>\n",
       "      <td>-5.153930e+06</td>\n",
       "      <td>-5.157130e+06</td>\n",
       "      <td>-5.158090e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_39</th>\n",
       "      <td>1.410553e+07</td>\n",
       "      <td>1.411987e+07</td>\n",
       "      <td>1.410783e+07</td>\n",
       "      <td>1.411574e+07</td>\n",
       "      <td>-4.932649e+06</td>\n",
       "      <td>-4.927177e+06</td>\n",
       "      <td>-4.953513e+06</td>\n",
       "      <td>-4.954217e+06</td>\n",
       "      <td>3.228486e+06</td>\n",
       "      <td>3.243974e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.645386e+06</td>\n",
       "      <td>-5.643914e+06</td>\n",
       "      <td>-3.459238e+06</td>\n",
       "      <td>-3.460870e+06</td>\n",
       "      <td>-3.459878e+06</td>\n",
       "      <td>-3.461062e+06</td>\n",
       "      <td>-5.156106e+06</td>\n",
       "      <td>-5.157866e+06</td>\n",
       "      <td>-5.154922e+06</td>\n",
       "      <td>-5.156394e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_13</th>\n",
       "      <td>1.412159e+07</td>\n",
       "      <td>1.410703e+07</td>\n",
       "      <td>1.409171e+07</td>\n",
       "      <td>1.411798e+07</td>\n",
       "      <td>-4.914921e+06</td>\n",
       "      <td>-4.943785e+06</td>\n",
       "      <td>-4.961129e+06</td>\n",
       "      <td>-4.948905e+06</td>\n",
       "      <td>3.250566e+06</td>\n",
       "      <td>3.230438e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.647434e+06</td>\n",
       "      <td>-5.641610e+06</td>\n",
       "      <td>-3.461734e+06</td>\n",
       "      <td>-3.461158e+06</td>\n",
       "      <td>-3.460966e+06</td>\n",
       "      <td>-3.461670e+06</td>\n",
       "      <td>-5.155690e+06</td>\n",
       "      <td>-5.155498e+06</td>\n",
       "      <td>-5.158602e+06</td>\n",
       "      <td>-5.156458e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 762880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3       \\\n",
       "channel_1   1.412883e+07  1.410380e+07  1.410851e+07  1.411343e+07   \n",
       "channel_34  1.411228e+07  1.410508e+07  1.411683e+07  1.411913e+07   \n",
       "channel_5   1.412431e+07  1.408847e+07  1.411033e+07  1.411014e+07   \n",
       "channel_39  1.410553e+07  1.411987e+07  1.410783e+07  1.411574e+07   \n",
       "channel_13  1.412159e+07  1.410703e+07  1.409171e+07  1.411798e+07   \n",
       "\n",
       "                  4             5             6             7       \\\n",
       "channel_1  -4.909065e+06 -4.948905e+06 -4.949609e+06 -4.952393e+06   \n",
       "channel_34 -4.927497e+06 -4.954985e+06 -4.941001e+06 -4.947593e+06   \n",
       "channel_5  -4.917001e+06 -4.967753e+06 -4.954601e+06 -4.961673e+06   \n",
       "channel_39 -4.932649e+06 -4.927177e+06 -4.953513e+06 -4.954217e+06   \n",
       "channel_13 -4.914921e+06 -4.943785e+06 -4.961129e+06 -4.948905e+06   \n",
       "\n",
       "                  8             9       ...        762870        762871  \\\n",
       "channel_1   3.253510e+06  3.231366e+06  ... -5.643658e+06 -5.641706e+06   \n",
       "channel_34  3.241126e+06  3.229286e+06  ... -5.643402e+06 -5.647914e+06   \n",
       "channel_5   3.247974e+06  3.218182e+06  ... -5.644170e+06 -5.642218e+06   \n",
       "channel_39  3.228486e+06  3.243974e+06  ... -5.645386e+06 -5.643914e+06   \n",
       "channel_13  3.250566e+06  3.230438e+06  ... -5.647434e+06 -5.641610e+06   \n",
       "\n",
       "                  762872        762873        762874        762875  \\\n",
       "channel_1  -3.462086e+06 -3.462502e+06 -3.461254e+06 -3.461862e+06   \n",
       "channel_34 -3.457190e+06 -3.457830e+06 -3.459910e+06 -3.461766e+06   \n",
       "channel_5  -3.459174e+06 -3.458790e+06 -3.462886e+06 -3.461894e+06   \n",
       "channel_39 -3.459238e+06 -3.460870e+06 -3.459878e+06 -3.461062e+06   \n",
       "channel_13 -3.461734e+06 -3.461158e+06 -3.460966e+06 -3.461670e+06   \n",
       "\n",
       "                  762876        762877        762878        762879  \n",
       "channel_1  -5.158634e+06 -5.159946e+06 -5.155018e+06 -5.154762e+06  \n",
       "channel_34 -5.158218e+06 -5.154698e+06 -5.154378e+06 -5.156010e+06  \n",
       "channel_5  -5.157930e+06 -5.153930e+06 -5.157130e+06 -5.158090e+06  \n",
       "channel_39 -5.156106e+06 -5.157866e+06 -5.154922e+06 -5.156394e+06  \n",
       "channel_13 -5.155690e+06 -5.155498e+06 -5.158602e+06 -5.156458e+06  \n",
       "\n",
       "[5 rows x 762880 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataframe from the pickle file\n",
    "import pickle\n",
    "dir = \"C:/Users/gusta/OneDrive/Skrivebord/KI & Data/Bachelor/LegeData\"\n",
    "with open(f\"{dir}/dataframe.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# keep these channels only, these are the indexes: \n",
    "\"\"\" \n",
    "Fp1 -> 0\n",
    "Fp2 -> 33\n",
    "F3  -> 4\n",
    "F4  -> 38\n",
    "C3  -> 12\n",
    "C4  -> 48\n",
    "P3  -> 20\n",
    "P4  -> 55\n",
    "O1  -> 26\n",
    "O2  -> 61\n",
    "F7  -> 6\n",
    "F8  -> 40\n",
    "T7  -> 14\n",
    "T8  -> 50\n",
    "P7  -> 22\n",
    "P8  -> 57\n",
    "Fz  -> 36\n",
    "Cz  -> 46\n",
    "Pz  -> 30 \n",
    "\n",
    "but add 1 to each index, since the first channel is channel_1\n",
    "\"\"\"\n",
    "\n",
    "df = df[[\"channel_1\", \"channel_34\", \"channel_5\", \"channel_39\", \"channel_13\", \"channel_49\", \"channel_21\", \"channel_56\", \"channel_27\", \"channel_62\", \"channel_7\", \"channel_41\", \"channel_15\", \"channel_51\", \"channel_23\", \"channel_58\", \"channel_37\", \"channel_47\", \"channel_31\", \"label\"]]\n",
    "df = df.T\n",
    "df.head()\n",
    "# print(df.iloc[:, :3])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for _ in range(10):\n",
    "    labels.append(np.repeat([1, 0], 149))\n",
    "labels = np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 2980\n",
      "Batch 1: Data shape torch.Size([1, 19, 256]), Label tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, df, labels):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        assert len(df.T) == len(labels) * 256, \"Mismatch between df rows and expected length from labels\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.T) // 256  # Ensure we have complete batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 256\n",
    "        end_idx = start_idx + 256\n",
    "        data = self.df.iloc[:,start_idx:end_idx].values\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(data).float(), torch.tensor(label).float()\n",
    "\n",
    "# Check dataset length\n",
    "dataset = EEGDataset(df, labels)\n",
    "print(f\"Length of dataset: {len(dataset)}\")\n",
    "\n",
    "# Check DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "for batch_ndx, (batch, label) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_ndx + 1}: Data shape {batch.shape}, Label {label}\")\n",
    "    break  # To print just the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762880\n",
      "762880\n"
     ]
    }
   ],
   "source": [
    "print(len(df.T))\n",
    "print(len(labels)*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1571]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "channels = 19\n",
    "sample_len = 256\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, channels), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(8*2 * (sample_len // 32), 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 128)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = EEGNet()\n",
    "print(net.forward(Variable(torch.Tensor(1,1,sample_len,channels))))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate function returns values of different criteria like accuracy, precision etc. \n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, params = [\"acc\"]):\n",
    "    results = []\n",
    "    model.eval()\n",
    "        \n",
    "    predicted = []\n",
    "    \n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # make shape (samples, 1, sample_len, channels)\n",
    "        inputs = inputs.reshape(-1, 1, sample_len, channels)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        predicted = model(inputs)\n",
    "        \n",
    "        predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(labels, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(labels, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(labels, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(labels, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(labels, np.round(predicted))\n",
    "            recall = recall_score(labels, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random data\n",
    "\n",
    "##### Data format:\n",
    "Datatype - float32 (both X and Y) <br>\n",
    "X.shape - (#samples, 1, #timepoints,  #channels) <br>\n",
    "Y.shape - (#samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels = 19\n",
    "sample_len = 256\n",
    "no_samples = 2980//10\n",
    "\n",
    "X_train = np.random.rand(no_samples, 1, sample_len, channels).astype('float32') # np.random.rand generates between [0, 1)\n",
    "y_train = np.round(np.random.rand(no_samples).astype('float32')) # binary data, so we round it to 0 or 1.\n",
    "\n",
    "X_val = np.random.rand(no_samples, 1, sample_len, channels).astype('float32')\n",
    "y_val = np.round(np.random.rand(no_samples).astype('float32'))\n",
    "\n",
    "X_test = np.random.rand(no_samples, 1, sample_len, channels).astype('float32')\n",
    "y_test = np.round(np.random.rand(no_samples).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 1: Data shape torch.Size([1, 19, 256]), Label shape torch.Size([1])\n",
      "Training set length: 2384\n",
      "Test set length: 596\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset class definition\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, df, labels):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.T) // 256  # Ensure we have complete batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 256\n",
    "        end_idx = start_idx + 256\n",
    "        data = self.df[:, start_idx:end_idx]\n",
    "        label = self.labels[idx*256]\n",
    "        return torch.tensor(data).float(), torch.tensor(label).float()\n",
    "\n",
    "# Assume df is a DataFrame where last row is labels, others are features\n",
    "# Transpose the dataframe to align features and labels correctly\n",
    "X = df.iloc[:-1, :]  # Features\n",
    "y = df.iloc[-1, :]   # Labels\n",
    "\n",
    "# Split into training and test sets using sklearn's train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.T, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset index for both X and y to avoid KeyError\n",
    "X_train = X_train.reset_index(drop=True).T.values\n",
    "X_test = X_test.reset_index(drop=True).T.values\n",
    "y_train = y_train.reset_index(drop=True).values\n",
    "y_test = y_test.reset_index(drop=True).values\n",
    "\n",
    "\n",
    "# Create Dataset and DataLoader for train and test\n",
    "train_dataset = EEGDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset = EEGDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Check DataLoader and print sizes of datasets and labels\n",
    "for batch_ndx, (batch, label) in enumerate(train_loader):\n",
    "    print(f\"Train Batch {batch_ndx + 1}: Data shape {batch.shape}, Label shape {label.shape}\")\n",
    "    break  # To print just the first batch\n",
    "\n",
    "print(f\"Training set length: {len(train_dataset)}\")\n",
    "print(f\"Test set length: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "0, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, ['acc']\n",
      "Training Loss  1632.6879984140396\n",
      "Train -  [1.0]\n",
      "Test -  [0.0]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "loops = 1\n",
    "\n",
    "for epoch in range(loops):  # loop over the dataset multiple times\n",
    "    print(\"\\nEpoch \", epoch)\n",
    "    net.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #make progress print every 200 samples\n",
    "        if i % 200 == 0:\n",
    "            print(i, end=\", \")\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # make shape (samples, 1, sample_len, channels)\n",
    "        inputs = inputs.reshape(-1, 1, sample_len, channels)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).reshape(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\"]\n",
    "    print(params)\n",
    "    print(\"Training Loss \", running_loss)\n",
    "    print(\"Train - \", evaluate(net, train_loader, params))\n",
    "    print(\"Test - \", evaluate(net, test_loader, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BACHELOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
