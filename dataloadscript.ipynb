{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes closed masking file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['#refs#', '#subsystem#', 'EEG', 'data', 'files', 'ii']>\n",
      "<HDF5 group \"/files\" (6 members)>\n",
      "    0     1     2     3     4     5     6     7     8     9     ...  5593  \\\n",
      "0    1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "51   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "52   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "53   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "54   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "\n",
      "    5594  5595  5596  5597  5598  5599  5600  5601  5602  \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "51   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "52   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "53   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "54   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5603 columns]\n",
      "(29, 5603)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "hf = h5py.File(f\"{dir}/eyesclosedmarked.mat\", \"r\")\n",
    "print(hf.keys())\n",
    "print(hf[\"files\"])\n",
    "# extract data from files group\n",
    "\n",
    "df = pd.DataFrame(hf[\"data\"][:]).T\n",
    "# keep only the first and the last 29 rows, since this is where there is eyes open data. And drop the 4th last patient since too little data.\n",
    "keep = np.concatenate([np.array([0]), np.arange(51, 80)])\n",
    "df = df.iloc[keep, :]\n",
    "# drop the 4th last patient\n",
    "df = df.drop(df.index[-4])\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# # Convert to a pandas dataframe\n",
    "# data = np.array(new_data).T\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes closed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "\n",
    "newdata = []\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "for i in range(10002, 10213 + 1):\n",
    "    file_name = f\"{i}_p01_epoched_60EpochsMarked.set\"\n",
    "    if os.path.isfile(os.path.join(dir, file_name)):\n",
    "        data = mne.io.read_epochs_eeglab(f\"{dir}/{file_name}\",verbose=False)\n",
    "        newdata.append(data.get_data())\n",
    "print(len(newdata))\n",
    "print(newdata[0].shape[0])\n",
    "print(newdata[1].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save newdata as a pickle file\n",
    "import pickle\n",
    "with open(f\"{dir}/closeddata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(newdata, f)\n",
    "\n",
    "#load newdata from pickle file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ID list to keep only relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(f\"{dir}/closeddata.pkl\", \"rb\") as f:\n",
    "    closeddata = pickle.load(f)\n",
    "\n",
    "keep = np.concatenate([np.array([0]), np.arange(51, 80)])\n",
    "# keep only the lists that are in keep array\n",
    "closeddata = [data for i, data in enumerate(closeddata) if i in keep]\n",
    "#delete 4th last list\n",
    "del closeddata[-4]\n",
    "print(len(closeddata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 28 28 28]\n",
      "Counter({np.int64(20): 4234, np.int64(7): 3618, np.int64(11): 3371, np.int64(10): 3043, np.int64(3): 2736, np.int64(8): 2701, np.int64(18): 2599, np.int64(17): 2592, np.int64(4): 2541, np.int64(9): 2257, np.int64(23): 2212, np.int64(5): 2051, np.int64(14): 1994, np.int64(6): 1911, np.int64(28): 1911, np.int64(22): 1879, np.int64(13): 1864, np.int64(1): 1859, np.int64(2): 1847, np.int64(15): 1824, np.int64(19): 1819, np.int64(12): 1816, np.int64(25): 1815, np.int64(27): 1810, np.int64(26): 1809, np.int64(0): 1807, np.int64(16): 1683, np.int64(21): 1372, np.int64(24): 816})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create a list of patient ids from one to 80 with each occuring as many timesa as closeddata[i].shape[0]\n",
    "\n",
    "patient_ids = np.arange(0, 29)\n",
    "patient_ids = np.repeat(patient_ids, [data.shape[0] for data in closeddata])\n",
    "print(patient_ids)\n",
    "#couint each entryie of each patient id\n",
    "from collections import Counter\n",
    "print(Counter(patient_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim lists for eyes closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to a list of numpy arrays\n",
    "labeldata = []\n",
    "for i in range(df.shape[0]):\n",
    "    labeldata.append(df.iloc[i].values)\n",
    "print(len(labeldata))\n",
    "print(labeldata[1].shape)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count occurrences of each number in list 'a'\n",
    "count_a = Counter(patient_ids)\n",
    "\n",
    "# Create a new list of lists where each sublist is trimmed to the count of its corresponding number\n",
    "trimmed_lists = []\n",
    "for num in range(29):  # Assuming numbers are from 0 to 28\n",
    "    occurrences = count_a[num]\n",
    "    trimmed_list = labeldata[num][:occurrences]\n",
    "    trimmed_lists.append(trimmed_list)\n",
    "\n",
    "\n",
    "# Print amount of zeros in each list\n",
    "for i, lst in enumerate(trimmed_lists):\n",
    "    print(f\"number of 0 entries in trimmed_list: {np.sum(trimmed_list == 0)}\")\n",
    "# looks good, 60 in each.\n",
    "\n",
    "\n",
    "\n",
    "# For each row in closeddata, keep only the epochs where the label is 0 in trimmed_lists\n",
    "trimmed_closed_data = []\n",
    "for i, data in enumerate(closeddata):\n",
    "    print(f\"shape of data: {data.shape}\")\n",
    "    labels = trimmed_lists[i]\n",
    "    trimmed_data = data[labels == 0]\n",
    "    trimmed_closed_data.append(trimmed_data)\n",
    "    print(f\"shape of trimmed_data: {trimmed_data.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Print the result\n",
    "# for i, data in enumerate(trimmed_closed_data):\n",
    "#     # print(f\"Data for {i}: {data[:5]}\")\n",
    "#     # print(len(data))\n",
    "\n",
    "#save trimmed_closed_data as a pickle file\n",
    "with open(f\"{dir}/trimmed_closed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trimmed_closed_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in opendata.pkl\n",
    "import pickle\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "with open(f\"{dir}/opendata.pkl\", \"rb\") as f:\n",
    "    opendata = pickle.load(f)\n",
    "    \n",
    "# drop 4th last patient\n",
    "del opendata[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in masking file, trim it down to correct size and apply it to data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File(f\"{dir}/eyesopenmarked.mat\", \"r\")\n",
    "print(hf.keys())\n",
    "print(hf[\"files\"])\n",
    "# extract data from files group\n",
    "\n",
    "dfopen = pd.DataFrame(hf[\"data\"][:]).T\n",
    "dfopen = dfopen[:30]\n",
    "dfopen = dfopen.drop(dfopen.index[-4])\n",
    "print(dfopen.shape)\n",
    "\n",
    "# convert df to a list of numpy arrays\n",
    "labeldata = []\n",
    "for i in range(dfopen.shape[0]):\n",
    "    labeldata.append(dfopen.iloc[i].values)\n",
    "print(len(labeldata))\n",
    "print(labeldata[1].shape)\n",
    "\n",
    "\n",
    "open_patient_ids = np.arange(0, 29)\n",
    "open_patient_ids = np.repeat(open_patient_ids, [data.shape[0] for data in opendata])\n",
    "print(open_patient_ids)\n",
    "print(f\" number of unique patient ids: {len(np.unique(open_patient_ids))}\")\n",
    "\n",
    "#couint each entryie of each patient id\n",
    "from collections import Counter\n",
    "print(Counter(open_patient_ids))\n",
    "\n",
    "# Count occurrences of each number in list 'a'\n",
    "count_a = Counter(open_patient_ids)\n",
    "\n",
    "\n",
    "# Create a new list of lists where each sublist is trimmed to the count of its corresponding number\n",
    "trimmed_lists = []\n",
    "for i, num in enumerate(np.unique(open_patient_ids)):  # Assuming numbers are from 0 to \n",
    "    occurrences = count_a[num]\n",
    "    trimmed_list = labeldata[i][:occurrences]\n",
    "    trimmed_lists.append(trimmed_list)\n",
    "\n",
    "\n",
    "# For each row in opendata, keep only the epochs where the label is 0 in trimmed_lists\n",
    "trimmed_open_data = []\n",
    "zeros_in_labls = []\n",
    "for i, data in enumerate(opendata):\n",
    "    print(f\"shape of data: {data.shape}\")\n",
    "    labels = trimmed_lists[i]\n",
    "    trimmed_data = data[labels == 0]\n",
    "    print(f\" number of zeros in labels: {np.sum(labels == 0)}\")\n",
    "    zeros_in_labls.append(np.sum(labels == 0))\n",
    "    trimmed_open_data.append(trimmed_data)\n",
    "    print(f\"shape of trimmed_data: {trimmed_data.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# create open_patients_ids from trimmed lists\n",
    "open_patient_ids = np.arange(0, 29)\n",
    "open_patient_ids = np.repeat(open_patient_ids, [data.shape[0] for data in trimmed_open_data])\n",
    "print(open_patient_ids)\n",
    "print(f\" number of unique patient ids: {len(np.unique(open_patient_ids))}\")\n",
    "\n",
    "\n",
    "# save trimmed_open_data as a pickle file\n",
    "with open(f\"{dir}/trimmed_open_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trimmed_open_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one big dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5             6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.000010 -0.000014 -0.000020 -1.990352e-05   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.000020 -0.000026 -0.000026 -2.479350e-05   \n",
      "2  0.000022  0.000018  0.000013  0.000008  0.000003  0.000001  9.871100e-07   \n",
      "3  0.000007  0.000003 -0.000001 -0.000004 -0.000007 -0.000008 -6.191659e-06   \n",
      "4  0.000013  0.000013  0.000012  0.000012  0.000010  0.000010  1.009186e-05   \n",
      "\n",
      "              7         8             9  ...          3791      3792  \\\n",
      "0 -2.007265e-05 -0.000019 -1.404443e-05  ... -1.092016e-05 -0.000010   \n",
      "1 -2.346011e-05 -0.000018 -1.718349e-05  ...  1.259601e-06  0.000002   \n",
      "2 -2.112761e-07 -0.000002 -1.798665e-06  ... -6.569762e-06 -0.000005   \n",
      "3 -4.011699e-06 -0.000002  4.808684e-07  ... -3.040970e-06 -0.000005   \n",
      "4  8.046945e-06  0.000007  4.599984e-06  ... -8.812295e-07  0.000002   \n",
      "\n",
      "           3793      3794      3795      3796      3797          3798  \\\n",
      "0 -6.451550e-06 -0.000002  0.000002  0.000005  0.000007  6.550796e-06   \n",
      "1  8.180189e-07 -0.000004 -0.000009 -0.000012 -0.000012 -1.015951e-05   \n",
      "2 -1.266182e-07  0.000004  0.000006  0.000008  0.000007  6.221105e-06   \n",
      "3 -4.692287e-06 -0.000005 -0.000004 -0.000003 -0.000002 -3.944589e-07   \n",
      "4  2.542886e-06  0.000005  0.000008  0.000012  0.000015  1.492380e-05   \n",
      "\n",
      "       3799  label  \n",
      "0  0.000006      1  \n",
      "1 -0.000007      1  \n",
      "2  0.000005      1  \n",
      "3  0.000002      1  \n",
      "4  0.000012      1  \n",
      "\n",
      "[5 rows x 3801 columns] (3215, 3801)\n"
     ]
    }
   ],
   "source": [
    "# load in trimmed_open_data.pkl and trimmed_closed_data.pkl and convert both to dataframes and stack them vertically\n",
    "import pickle\n",
    "import pandas as pd\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "with open(f\"{dir}/trimmed_open_data.pkl\", \"rb\") as f:\n",
    "    trimmed_open_data = pickle.load(f)\n",
    "\n",
    "with open(f\"{dir}/trimmed_closed_data.pkl\", \"rb\") as f:\n",
    "    trimmed_closed_data = pickle.load(f)\n",
    "\n",
    "\n",
    "# convert trimmed_closed_data to a dataframe\n",
    "closed_df = pd.DataFrame()\n",
    "for i, data in enumerate(trimmed_closed_data):\n",
    "    data = data.reshape(60, -1)\n",
    "    df = pd.DataFrame(data)\n",
    "    closed_df = pd.concat([closed_df, df], axis=0)\n",
    "closed_df[\"label\"] = 1\n",
    "\n",
    "open_df = pd.DataFrame()\n",
    "for i, data in enumerate(trimmed_open_data):\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    df = pd.DataFrame(data)\n",
    "    open_df = pd.concat([open_df, df], axis=0)\n",
    "open_df[\"label\"] = 0\n",
    "\n",
    "# stack the two dataframes vertically\n",
    "df = pd.concat([closed_df, open_df], axis=0)\n",
    "print(df.head(), df.shape)\n",
    "\n",
    "# save df as a pickle file\n",
    "with open(f\"{dir}/df_EOandEC.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Patient ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740 1475\n",
      "(3215, 3802)\n",
      "          0         1         2         3         4         5             6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.000010 -0.000014 -0.000020 -1.990352e-05   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.000020 -0.000026 -0.000026 -2.479350e-05   \n",
      "2  0.000022  0.000018  0.000013  0.000008  0.000003  0.000001  9.871100e-07   \n",
      "3  0.000007  0.000003 -0.000001 -0.000004 -0.000007 -0.000008 -6.191659e-06   \n",
      "4  0.000013  0.000013  0.000012  0.000012  0.000010  0.000010  1.009186e-05   \n",
      "\n",
      "              7         8             9  ...      3792          3793  \\\n",
      "0 -2.007265e-05 -0.000019 -1.404443e-05  ... -0.000010 -6.451550e-06   \n",
      "1 -2.346011e-05 -0.000018 -1.718349e-05  ...  0.000002  8.180189e-07   \n",
      "2 -2.112761e-07 -0.000002 -1.798665e-06  ... -0.000005 -1.266182e-07   \n",
      "3 -4.011699e-06 -0.000002  4.808684e-07  ... -0.000005 -4.692287e-06   \n",
      "4  8.046945e-06  0.000007  4.599984e-06  ...  0.000002  2.542886e-06   \n",
      "\n",
      "       3794      3795      3796      3797          3798      3799  label  \\\n",
      "0 -0.000002  0.000002  0.000005  0.000007  6.550796e-06  0.000006      1   \n",
      "1 -0.000004 -0.000009 -0.000012 -0.000012 -1.015951e-05 -0.000007      1   \n",
      "2  0.000004  0.000006  0.000008  0.000007  6.221105e-06  0.000005      1   \n",
      "3 -0.000005 -0.000004 -0.000003 -0.000002 -3.944589e-07  0.000002      1   \n",
      "4  0.000005  0.000008  0.000012  0.000015  1.492380e-05  0.000012      1   \n",
      "\n",
      "   patient_id  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "\n",
      "[5 rows x 3802 columns]\n"
     ]
    }
   ],
   "source": [
    "closed_patient_ids = np.repeat(np.arange(0, 29), 60)\n",
    "\n",
    "print(len(closed_patient_ids), len(open_patient_ids))\n",
    "patient_ids = np.concatenate([closed_patient_ids, open_patient_ids])\n",
    "\n",
    "# attach patient ids to df\n",
    "df[\"patient_id\"] = patient_ids\n",
    "print(df.shape)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data patientwise(global patient parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before scaling:           0         1         2        3         4         5         6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.00001 -0.000014 -0.000020 -0.000020   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.00002 -0.000026 -0.000026 -0.000025   \n",
      "\n",
      "          7         8         9  ...      3792          3793      3794  \\\n",
      "0 -0.000020 -0.000019 -0.000014  ... -0.000010 -6.451550e-06 -0.000002   \n",
      "1 -0.000023 -0.000018 -0.000017  ...  0.000002  8.180189e-07 -0.000004   \n",
      "\n",
      "       3795      3796      3797      3798      3799  label  patient_id  \n",
      "0  0.000002  0.000005  0.000007  0.000007  0.000006      1           0  \n",
      "1 -0.000009 -0.000012 -0.000012 -0.000010 -0.000007      1           0  \n",
      "\n",
      "[2 rows x 3802 columns]\n",
      "after scaling: [[-0.22054073 -0.23624156 -0.17988051 ...  0.60395375  1.\n",
      "   0.        ]\n",
      " [-0.23374289 -0.28206085 -0.22675689 ... -0.11500413  1.\n",
      "   0.        ]]\n",
      "min and max: -1.0, 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "y = df[\"label\"].values\n",
    "patient_ids = df[\"patient_id\"].values\n",
    "\n",
    "# Normalize per patient (within training and test sets)\n",
    "print(f\"before scaling: {df.head(2)}\")\n",
    "df = df.drop(columns=[\"label\", \"patient_id\"])  # Drop the label and patient id columns\n",
    "df_norm = []\n",
    "for patient_id in np.unique(patient_ids):\n",
    "    patient_data = df[patient_ids == patient_id]\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    patient_data_scaled = scaler.fit_transform(patient_data)\n",
    "    df_norm.append(patient_data_scaled)\n",
    "\n",
    "df_norm = np.concatenate(df_norm, axis=0)\n",
    "# Add labels back\n",
    "df_norm = np.concatenate([df_norm, y.reshape(-1, 1)], axis=1)\n",
    "# Add patient ids back\n",
    "df_norm = np.concatenate([df_norm, patient_ids.reshape(-1, 1)], axis=1)\n",
    "print(f\"after scaling: {df_norm[:2]}\")\n",
    "print(f\"min and max: {np.min(df_norm)}, {np.max(df_norm[:, :-2])}\")\n",
    "\n",
    "# save df_norm as a pickle file\n",
    "with open(f\"{dir}/df_EOandEC_norm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_norm, f)\n",
    "\n",
    "# save in a differnt format also\n",
    "df = pd.DataFrame(df_norm)\n",
    "df.to_csv(f\"{dir}/df_EOandEC_norm.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: -1.0, max: 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check min and max values\n",
    "print(f\"min: {np.min(df_norm)}, max: {np.max(df_norm[:, :-2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of spectrograms: 3215\n",
      "3927\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.186564  0.475278  0.505854  0.306700  0.255097  0.557123  0.555072   \n",
      "1  0.131151  0.520671  0.447478  0.456006  0.052131  0.583297  0.527655   \n",
      "2  0.123682  0.148802  0.332623  0.198912  0.240235  0.298129  0.357936   \n",
      "3  0.168667  0.463728  0.337087  0.306425  0.304572  0.543767  0.367835   \n",
      "4  0.143401  0.420038  0.098637  0.138659  0.324467  0.524166  0.083871   \n",
      "\n",
      "          7         8         9  ...      3919      3920      3921      3922  \\\n",
      "0  0.407374  0.221913  0.021099  ...  0.001207  0.002463  0.000491  0.005581   \n",
      "1  0.536725  0.081143  0.052932  ...  0.002277  0.001954  0.001542  0.003579   \n",
      "2  0.325636  0.169057  0.191902  ...  0.002602  0.001009  0.000062  0.007482   \n",
      "3  0.455260  0.288131  0.157854  ...  0.001342  0.001138  0.001100  0.000432   \n",
      "4  0.324291  0.224512  0.130821  ...  0.001786  0.002207  0.000786  0.001823   \n",
      "\n",
      "       3923      3924      3925      3926  label  patient_id  \n",
      "0  0.001443  0.003982  0.002276  0.005611      1           0  \n",
      "1  0.000753  0.003467  0.003439  0.003056      1           0  \n",
      "2  0.000660  0.002182  0.002051  0.005261      1           0  \n",
      "3  0.001260  0.003974  0.003283  0.002847      1           0  \n",
      "4  0.000753  0.002303  0.003585  0.007058      1           0  \n",
      "\n",
      "[5 rows x 3929 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "\n",
    "reshaped_data = df_norm[:, :-2]\n",
    "\n",
    "fs = 200  # Sampling frequency (in Hz)\n",
    "nperseg = fs/2  # Length of each segment for STFT (typically a power of 2)\n",
    "\n",
    "# create empty list for the spectrograms, each channel will have its own list\n",
    "spectrograms = [[] for _ in range(reshaped_data.shape[0])]\n",
    "print(f\"shape of spectrograms: {len(spectrograms)}\")\n",
    "\n",
    "for i, epoch in enumerate(reshaped_data): # loop over datarows\n",
    "    frequencies, times, Zxx = stft(epoch, fs, nperseg=nperseg)\n",
    "    spectrogram = np.abs(Zxx)  # Shape: (n_freq_bins, n_time_segments)\n",
    "    # print(f\"shape of spectrogram: {spectrogram.shape}\")\n",
    "\n",
    "    # Flatten the spectrogram of this channel\n",
    "    spectrogram_flattened = spectrogram.flatten()  # Flatten to 1D array\n",
    "    \n",
    "    # Append to list\n",
    "    spectrograms[i] = spectrogram_flattened\n",
    "\n",
    "print(len(spectrograms[0]))\n",
    "\n",
    "# save spectrograms as a pickle file\n",
    "spectrograms = np.array(spectrograms)\n",
    "df = pd.DataFrame(spectrograms)\n",
    "df[\"label\"] = y\n",
    "df[\"patient_id\"] = patient_ids\n",
    "print(df.head())\n",
    "\n",
    "with open(f\"{dir}/hospital_spectrograms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(spectrograms, f)\n",
    "\n",
    "# save as a csv file\n",
    "df.to_csv(f\"{dir}/hospital_spectrograms.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Reg Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy for Patient 0: 90.29%\n",
      "Model accuracy for Patient 1: 99.43%\n",
      "Model accuracy for Patient 2: 100.00%\n",
      "Model accuracy for Patient 3: 98.12%\n",
      "Model accuracy for Patient 4: 100.00%\n",
      "Model accuracy for Patient 5: 97.26%\n",
      "Model accuracy for Patient 6: 100.00%\n",
      "Model accuracy for Patient 7: 97.95%\n",
      "Model accuracy for Patient 8: 100.00%\n",
      "Model accuracy for Patient 9: 98.70%\n",
      "Model accuracy for Patient 10: 99.07%\n",
      "Model accuracy for Patient 11: 96.70%\n",
      "Model accuracy for Patient 12: 100.00%\n",
      "Model accuracy for Patient 13: 99.03%\n",
      "Model accuracy for Patient 14: 100.00%\n",
      "Model accuracy for Patient 15: 100.00%\n",
      "Model accuracy for Patient 16: 96.39%\n",
      "Model accuracy for Patient 17: 100.00%\n",
      "Model accuracy for Patient 18: 100.00%\n",
      "Model accuracy for Patient 19: 99.36%\n",
      "Model accuracy for Patient 20: 98.10%\n",
      "Model accuracy for Patient 21: 98.94%\n",
      "Model accuracy for Patient 22: 99.09%\n",
      "Model accuracy for Patient 23: 100.00%\n",
      "Model accuracy for Patient 24: 100.00%\n",
      "Model accuracy for Patient 25: 99.19%\n",
      "Model accuracy for Patient 26: 98.48%\n",
      "Model accuracy for Patient 27: 100.00%\n",
      "Model accuracy for Patient 28: 69.77%\n",
      "Average accuracy across patients: 97.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "accs = []\n",
    "\n",
    "# Initialize Leave-One-Group-Out cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "patient_ids = df_norm[:, -1]\n",
    "y = df_norm[:, -2]\n",
    "data = df_norm[:, :-2]\n",
    "\n",
    "# Train-test split using Leave-One-Group-Out\n",
    "for i, (train_index, test_index) in enumerate(logo.split(data, y, groups=patient_ids)):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000, verbose=1,class_weight=\"balanced\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accs.append(accuracy)\n",
    "    print(f'Model accuracy for Patient {i}: {accuracy*100:.2f}%')\n",
    "\n",
    "# Print the average accuracy over all patients\n",
    "print(f'Average accuracy across patients: {np.mean(accs)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".LogReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
