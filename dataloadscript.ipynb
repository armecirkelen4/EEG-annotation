{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes closed masking file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['#refs#', '#subsystem#', 'EEG', 'data', 'files', 'ii']>\n",
      "<HDF5 group \"/files\" (6 members)>\n",
      "    0     1     2     3     4     5     6     7     8     9     ...  5593  \\\n",
      "0    1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "51   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "52   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "53   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
      "54   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  ...   0.0   \n",
      "\n",
      "    5594  5595  5596  5597  5598  5599  5600  5601  5602  \n",
      "0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "51   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "52   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "53   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "54   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5603 columns]\n",
      "(29, 5603)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "hf = h5py.File(f\"{dir}/eyesclosedmarked.mat\", \"r\")\n",
    "print(hf.keys())\n",
    "print(hf[\"files\"])\n",
    "# extract data from files group\n",
    "\n",
    "df = pd.DataFrame(hf[\"data\"][:]).T\n",
    "# keep only the first and the last 29 rows, since this is where there is eyes open data. And drop the 4th last patient since too little data.\n",
    "keep = np.concatenate([np.array([0]), np.arange(51, 80)])\n",
    "df = df.iloc[keep, :]\n",
    "# drop the 4th last patient\n",
    "df = df.drop(df.index[-4])\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# # Convert to a pandas dataframe\n",
    "# data = np.array(new_data).T\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes closed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\utils\\check.py:391\u001b[0m, in \u001b[0;36m_soft_import\u001b[1;34m(name, purpose, strict)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymatreader'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\io\\eeglab\\_eeglab.py:76\u001b[0m, in \u001b[0;36m_readmat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     read_mat \u001b[38;5;241m=\u001b[39m \u001b[43m_import_pymatreader_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEEGLAB I/O\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# pymatreader not installed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\utils\\check.py:174\u001b[0m, in \u001b[0;36m_import_pymatreader_funcs\u001b[1;34m(purpose)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_import_pymatreader_funcs\u001b[39m(purpose):\n\u001b[1;32m--> 174\u001b[0m     pymatreader \u001b[38;5;241m=\u001b[39m \u001b[43m_soft_import\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpymatreader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurpose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pymatreader\u001b[38;5;241m.\u001b[39mread_mat\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\utils\\check.py:395\u001b[0m, in \u001b[0;36m_soft_import\u001b[1;34m(name, purpose, strict)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurpose\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to work, the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m module is needed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut it could not be imported.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    399\u001b[0m             (\n\u001b[0;32m    400\u001b[0m                 indent(\n\u001b[0;32m    401\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse the following installation method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate for your environment:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m                 ),\n\u001b[0;32m    404\u001b[0m                 indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    405\u001b[0m                 indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    406\u001b[0m             )\n\u001b[0;32m    407\u001b[0m         )\n\u001b[0;32m    408\u001b[0m     )\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For EEGLAB I/O to work, the pymatreader module is needed, but it could not be imported.\n              use the following installation method appropriate for your environment:\n              'pip install pymatreader'\n              'conda install -c conda-forge pymatreader'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_p01_epoched_60EpochsMarked.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mdir\u001b[39m, file_name)):\n\u001b[1;32m----> 9\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_epochs_eeglab\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         newdata\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mget_data())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(newdata))\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:396\u001b[0m, in \u001b[0;36mread_epochs_eeglab\u001b[1;34m(input_fname, events, event_id, eog, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;129m@fill_doc\u001b[39m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_epochs_eeglab\u001b[39m(\n\u001b[0;32m    339\u001b[0m     input_fname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    346\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochsEEGLAB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reader function for EEGLAB epochs files.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.11.0\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[43mEpochsEEGLAB\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_fname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_fname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43meog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muint16_codec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmontage_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmontage_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epochs\n",
      "File \u001b[1;32m<decorator-gen-265>:10\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, input_fname, events, event_id, tmin, baseline, reject, flat, reject_tmin, reject_tmax, eog, uint16_codec, montage_units, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:604\u001b[0m, in \u001b[0;36mEpochsEEGLAB.__init__\u001b[1;34m(self, input_fname, events, event_id, tmin, baseline, reject, flat, reject_tmin, reject_tmax, eog, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    600\u001b[0m ):\n\u001b[0;32m    601\u001b[0m     input_fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m    602\u001b[0m         _check_fname(fname\u001b[38;5;241m=\u001b[39minput_fname, must_exist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    603\u001b[0m     )\n\u001b[1;32m--> 604\u001b[0m     eeg \u001b[38;5;241m=\u001b[39m \u001b[43m_check_load_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    607\u001b[0m         (events \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m event_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (events \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m event_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    609\u001b[0m     ):\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoth `events` and `event_id` must be None or not None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:73\u001b[0m, in \u001b[0;36m_check_load_mat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_load_mat\u001b[39m(fname, uint16_codec):\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if the mat struct contains 'EEG'.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     eeg \u001b[38;5;241m=\u001b[39m \u001b[43m_readmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muint16_codec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEEG\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m eeg:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading an ALLEEG array is not supported. Please contact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmne-python developers for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\mne\\io\\eeglab\\_eeglab.py:78\u001b[0m, in \u001b[0;36m_readmat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     76\u001b[0m     read_mat \u001b[38;5;241m=\u001b[39m _import_pymatreader_funcs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEEGLAB I/O\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# pymatreader not installed\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     eeg \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_for_scipy_mat_struct(eeg)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_mio5_utils.pyx:665\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:734\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:11\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:18\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\TMS-EEG\\Desktop\\.LogReg\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1624\u001b[0m, in \u001b[0;36m_squeeze_dispatcher\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     a \u001b[38;5;241m=\u001b[39m concatenate((a,) \u001b[38;5;241m*\u001b[39m repeats)[:new_size]\n\u001b[0;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[1;32m-> 1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_squeeze_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import os\n",
    "\n",
    "newdata = []\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "for i in range(10002, 10213 + 1):\n",
    "    file_name = f\"{i}_p01_epoched_60EpochsMarked.set\"\n",
    "    if os.path.isfile(os.path.join(dir, file_name)):\n",
    "        data = mne.io.read_epochs_eeglab(f\"{dir}/{file_name}\",verbose=False)\n",
    "        newdata.append(data.get_data())\n",
    "print(len(newdata))\n",
    "print(newdata[0].shape[0])\n",
    "print(newdata[1].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save newdata as a pickle file\n",
    "import pickle\n",
    "with open(f\"{dir}/closeddata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(newdata, f)\n",
    "\n",
    "#load newdata from pickle file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ID list to keep only relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(f\"{dir}/closeddata.pkl\", \"rb\") as f:\n",
    "    closeddata = pickle.load(f)\n",
    "\n",
    "keep = np.concatenate([np.array([0]), np.arange(51, 80)])\n",
    "# keep only the lists that are in keep array\n",
    "closeddata = [data for i, data in enumerate(closeddata) if i in keep]\n",
    "#delete 4th last list\n",
    "del closeddata[-4]\n",
    "print(len(closeddata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 28 28 28]\n",
      "Counter({np.int64(20): 4234, np.int64(7): 3618, np.int64(11): 3371, np.int64(10): 3043, np.int64(3): 2736, np.int64(8): 2701, np.int64(18): 2599, np.int64(17): 2592, np.int64(4): 2541, np.int64(9): 2257, np.int64(23): 2212, np.int64(5): 2051, np.int64(14): 1994, np.int64(6): 1911, np.int64(28): 1911, np.int64(22): 1879, np.int64(13): 1864, np.int64(1): 1859, np.int64(2): 1847, np.int64(15): 1824, np.int64(19): 1819, np.int64(12): 1816, np.int64(25): 1815, np.int64(27): 1810, np.int64(26): 1809, np.int64(0): 1807, np.int64(16): 1683, np.int64(21): 1372, np.int64(24): 816})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create a list of patient ids from one to 80 with each occuring as many timesa as closeddata[i].shape[0]\n",
    "\n",
    "patient_ids = np.arange(0, 29)\n",
    "patient_ids = np.repeat(patient_ids, [data.shape[0] for data in closeddata])\n",
    "print(patient_ids)\n",
    "#couint each entryie of each patient id\n",
    "from collections import Counter\n",
    "print(Counter(patient_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim lists for eyes closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "(5603,)\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "number of 0 entries in trimmed_list: 60\n",
      "shape of data: (1807, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1859, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1847, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2736, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2541, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2051, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1911, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (3618, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2701, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2257, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (3043, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (3371, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1816, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1864, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1994, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1824, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1683, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2592, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2599, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1819, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (4234, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1372, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1879, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (2212, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (816, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1815, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1809, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1810, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n",
      "shape of data: (1911, 19, 200)\n",
      "shape of trimmed_data: (60, 19, 200)\n"
     ]
    }
   ],
   "source": [
    "# convert df to a list of numpy arrays\n",
    "labeldata = []\n",
    "for i in range(df.shape[0]):\n",
    "    labeldata.append(df.iloc[i].values)\n",
    "print(len(labeldata))\n",
    "print(labeldata[1].shape)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count occurrences of each number in list 'a'\n",
    "count_a = Counter(patient_ids)\n",
    "\n",
    "# Create a new list of lists where each sublist is trimmed to the count of its corresponding number\n",
    "trimmed_lists = []\n",
    "for num in range(29):  # Assuming numbers are from 0 to 28\n",
    "    occurrences = count_a[num]\n",
    "    trimmed_list = labeldata[num][:occurrences]\n",
    "    trimmed_lists.append(trimmed_list)\n",
    "\n",
    "\n",
    "# Print amount of zeros in each list\n",
    "for i, lst in enumerate(trimmed_lists):\n",
    "    print(f\"number of 0 entries in trimmed_list: {np.sum(trimmed_list == 0)}\")\n",
    "# looks good, 60 in each.\n",
    "\n",
    "\n",
    "\n",
    "# For each row in closeddata, keep only the epochs where the label is 0 in trimmed_lists\n",
    "trimmed_closed_data = []\n",
    "for i, data in enumerate(closeddata):\n",
    "    print(f\"shape of data: {data.shape}\")\n",
    "    labels = trimmed_lists[i]\n",
    "    trimmed_data = data[labels == 0]\n",
    "    trimmed_closed_data.append(trimmed_data)\n",
    "    print(f\"shape of trimmed_data: {trimmed_data.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Print the result\n",
    "# for i, data in enumerate(trimmed_closed_data):\n",
    "#     # print(f\"Data for {i}: {data[:5]}\")\n",
    "#     # print(len(data))\n",
    "\n",
    "#save trimmed_closed_data as a pickle file\n",
    "with open(f\"{dir}/trimmed_closed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trimmed_closed_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eyes open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in opendata.pkl\n",
    "import pickle\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "with open(f\"{dir}/opendata.pkl\", \"rb\") as f:\n",
    "    opendata = pickle.load(f)\n",
    "    \n",
    "# drop 4th last patient\n",
    "del opendata[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in masking file, trim it down to correct size and apply it to data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['#refs#', '#subsystem#', 'EEG', 'data', 'files', 'ii']>\n",
      "<HDF5 group \"/files\" (6 members)>\n",
      "(29, 4234)\n",
      "29\n",
      "(4234,)\n",
      "[ 0  0  0 ... 28 28 28]\n",
      " number of unique patient ids: 29\n",
      "Counter({np.int64(20): 4234, np.int64(9): 3618, np.int64(12): 3371, np.int64(2): 3123, np.int64(11): 3043, np.int64(5): 2736, np.int64(18): 2599, np.int64(17): 2592, np.int64(6): 2541, np.int64(10): 2257, np.int64(23): 2212, np.int64(7): 2051, np.int64(15): 1994, np.int64(8): 1911, np.int64(28): 1911, np.int64(1): 1901, np.int64(22): 1879, np.int64(14): 1864, np.int64(3): 1859, np.int64(4): 1847, np.int64(19): 1819, np.int64(13): 1816, np.int64(25): 1815, np.int64(27): 1810, np.int64(26): 1809, np.int64(0): 1807, np.int64(16): 1683, np.int64(21): 1372, np.int64(24): 816})\n",
      "shape of data: (1807, 19, 200)\n",
      " number of zeros in labels: 43\n",
      "shape of trimmed_data: (43, 19, 200)\n",
      "shape of data: (1901, 19, 200)\n",
      " number of zeros in labels: 116\n",
      "shape of trimmed_data: (116, 19, 200)\n",
      "shape of data: (3123, 19, 200)\n",
      " number of zeros in labels: 19\n",
      "shape of trimmed_data: (19, 19, 200)\n",
      "shape of data: (1859, 19, 200)\n",
      " number of zeros in labels: 100\n",
      "shape of trimmed_data: (100, 19, 200)\n",
      "shape of data: (1847, 19, 200)\n",
      " number of zeros in labels: 16\n",
      "shape of trimmed_data: (16, 19, 200)\n",
      "shape of data: (2736, 19, 200)\n",
      " number of zeros in labels: 13\n",
      "shape of trimmed_data: (13, 19, 200)\n",
      "shape of data: (2541, 19, 200)\n",
      " number of zeros in labels: 44\n",
      "shape of trimmed_data: (44, 19, 200)\n",
      "shape of data: (2051, 19, 200)\n",
      " number of zeros in labels: 86\n",
      "shape of trimmed_data: (86, 19, 200)\n",
      "shape of data: (1911, 19, 200)\n",
      " number of zeros in labels: 42\n",
      "shape of trimmed_data: (42, 19, 200)\n",
      "shape of data: (3618, 19, 200)\n",
      " number of zeros in labels: 17\n",
      "shape of trimmed_data: (17, 19, 200)\n",
      "shape of data: (2257, 19, 200)\n",
      " number of zeros in labels: 48\n",
      "shape of trimmed_data: (48, 19, 200)\n",
      "shape of data: (3043, 19, 200)\n",
      " number of zeros in labels: 31\n",
      "shape of trimmed_data: (31, 19, 200)\n",
      "shape of data: (3371, 19, 200)\n",
      " number of zeros in labels: 22\n",
      "shape of trimmed_data: (22, 19, 200)\n",
      "shape of data: (1816, 19, 200)\n",
      " number of zeros in labels: 43\n",
      "shape of trimmed_data: (43, 19, 200)\n",
      "shape of data: (1864, 19, 200)\n",
      " number of zeros in labels: 50\n",
      "shape of trimmed_data: (50, 19, 200)\n",
      "shape of data: (1994, 19, 200)\n",
      " number of zeros in labels: 16\n",
      "shape of trimmed_data: (16, 19, 200)\n",
      "shape of data: (1683, 19, 200)\n",
      " number of zeros in labels: 23\n",
      "shape of trimmed_data: (23, 19, 200)\n",
      "shape of data: (2592, 19, 200)\n",
      " number of zeros in labels: 87\n",
      "shape of trimmed_data: (87, 19, 200)\n",
      "shape of data: (2599, 19, 200)\n",
      " number of zeros in labels: 66\n",
      "shape of trimmed_data: (66, 19, 200)\n",
      "shape of data: (1819, 19, 200)\n",
      " number of zeros in labels: 96\n",
      "shape of trimmed_data: (96, 19, 200)\n",
      "shape of data: (4234, 19, 200)\n",
      " number of zeros in labels: 45\n",
      "shape of trimmed_data: (45, 19, 200)\n",
      "shape of data: (1372, 19, 200)\n",
      " number of zeros in labels: 34\n",
      "shape of trimmed_data: (34, 19, 200)\n",
      "shape of data: (1879, 19, 200)\n",
      " number of zeros in labels: 50\n",
      "shape of trimmed_data: (50, 19, 200)\n",
      "shape of data: (2212, 19, 200)\n",
      " number of zeros in labels: 25\n",
      "shape of trimmed_data: (25, 19, 200)\n",
      "shape of data: (816, 19, 200)\n",
      " number of zeros in labels: 75\n",
      "shape of trimmed_data: (75, 19, 200)\n",
      "shape of data: (1815, 19, 200)\n",
      " number of zeros in labels: 63\n",
      "shape of trimmed_data: (63, 19, 200)\n",
      "shape of data: (1809, 19, 200)\n",
      " number of zeros in labels: 72\n",
      "shape of trimmed_data: (72, 19, 200)\n",
      "shape of data: (1810, 19, 200)\n",
      " number of zeros in labels: 107\n",
      "shape of trimmed_data: (107, 19, 200)\n",
      "shape of data: (1911, 19, 200)\n",
      " number of zeros in labels: 26\n",
      "shape of trimmed_data: (26, 19, 200)\n",
      "[ 0  0  0 ... 28 28 28]\n",
      " number of unique patient ids: 29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "hf = h5py.File(f\"{dir}/eyesopenmarked.mat\", \"r\")\n",
    "print(hf.keys())\n",
    "print(hf[\"files\"])\n",
    "# extract data from files group\n",
    "\n",
    "dfopen = pd.DataFrame(hf[\"data\"][:]).T\n",
    "dfopen = dfopen[:30]\n",
    "dfopen = dfopen.drop(dfopen.index[-4])\n",
    "print(dfopen.shape)\n",
    "\n",
    "# convert df to a list of numpy arrays\n",
    "labeldata = []\n",
    "for i in range(dfopen.shape[0]):\n",
    "    labeldata.append(dfopen.iloc[i].values)\n",
    "print(len(labeldata))\n",
    "print(labeldata[1].shape)\n",
    "\n",
    "\n",
    "open_patient_ids = np.arange(0, 29)\n",
    "open_patient_ids = np.repeat(open_patient_ids, [data.shape[0] for data in opendata])\n",
    "print(open_patient_ids)\n",
    "print(f\" number of unique patient ids: {len(np.unique(open_patient_ids))}\")\n",
    "\n",
    "#couint each entryie of each patient id\n",
    "from collections import Counter\n",
    "print(Counter(open_patient_ids))\n",
    "\n",
    "# Count occurrences of each number in list 'a'\n",
    "count_a = Counter(open_patient_ids)\n",
    "\n",
    "\n",
    "# Create a new list of lists where each sublist is trimmed to the count of its corresponding number\n",
    "trimmed_lists = []\n",
    "for i, num in enumerate(np.unique(open_patient_ids)):  # Assuming numbers are from 0 to \n",
    "    occurrences = count_a[num]\n",
    "    trimmed_list = labeldata[i][:occurrences]\n",
    "    trimmed_lists.append(trimmed_list)\n",
    "\n",
    "\n",
    "# For each row in opendata, keep only the epochs where the label is 0 in trimmed_lists\n",
    "trimmed_open_data = []\n",
    "zeros_in_labls = []\n",
    "for i, data in enumerate(opendata):\n",
    "    print(f\"shape of data: {data.shape}\")\n",
    "    labels = trimmed_lists[i]\n",
    "    trimmed_data = data[labels == 0]\n",
    "    print(f\" number of zeros in labels: {np.sum(labels == 0)}\")\n",
    "    zeros_in_labls.append(np.sum(labels == 0))\n",
    "    trimmed_open_data.append(trimmed_data)\n",
    "    print(f\"shape of trimmed_data: {trimmed_data.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# create open_patients_ids from trimmed lists\n",
    "open_patient_ids = np.arange(0, 29)\n",
    "open_patient_ids = np.repeat(open_patient_ids, [data.shape[0] for data in trimmed_open_data])\n",
    "print(open_patient_ids)\n",
    "print(f\" number of unique patient ids: {len(np.unique(open_patient_ids))}\")\n",
    "\n",
    "\n",
    "# save trimmed_open_data as a pickle file\n",
    "with open(f\"{dir}/trimmed_open_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trimmed_open_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one big dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5             6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.000010 -0.000014 -0.000020 -1.990352e-05   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.000020 -0.000026 -0.000026 -2.479350e-05   \n",
      "2  0.000022  0.000018  0.000013  0.000008  0.000003  0.000001  9.871100e-07   \n",
      "3  0.000007  0.000003 -0.000001 -0.000004 -0.000007 -0.000008 -6.191659e-06   \n",
      "4  0.000013  0.000013  0.000012  0.000012  0.000010  0.000010  1.009186e-05   \n",
      "\n",
      "              7         8             9  ...          3791      3792  \\\n",
      "0 -2.007265e-05 -0.000019 -1.404443e-05  ... -1.092016e-05 -0.000010   \n",
      "1 -2.346011e-05 -0.000018 -1.718349e-05  ...  1.259601e-06  0.000002   \n",
      "2 -2.112761e-07 -0.000002 -1.798665e-06  ... -6.569762e-06 -0.000005   \n",
      "3 -4.011699e-06 -0.000002  4.808684e-07  ... -3.040970e-06 -0.000005   \n",
      "4  8.046945e-06  0.000007  4.599984e-06  ... -8.812295e-07  0.000002   \n",
      "\n",
      "           3793      3794      3795      3796      3797          3798  \\\n",
      "0 -6.451550e-06 -0.000002  0.000002  0.000005  0.000007  6.550796e-06   \n",
      "1  8.180189e-07 -0.000004 -0.000009 -0.000012 -0.000012 -1.015951e-05   \n",
      "2 -1.266182e-07  0.000004  0.000006  0.000008  0.000007  6.221105e-06   \n",
      "3 -4.692287e-06 -0.000005 -0.000004 -0.000003 -0.000002 -3.944589e-07   \n",
      "4  2.542886e-06  0.000005  0.000008  0.000012  0.000015  1.492380e-05   \n",
      "\n",
      "       3799  label  \n",
      "0  0.000006      1  \n",
      "1 -0.000007      1  \n",
      "2  0.000005      1  \n",
      "3  0.000002      1  \n",
      "4  0.000012      1  \n",
      "\n",
      "[5 rows x 3801 columns] (3215, 3801)\n"
     ]
    }
   ],
   "source": [
    "# load in trimmed_open_data.pkl and trimmed_closed_data.pkl and convert both to dataframes and stack them vertically\n",
    "import pickle\n",
    "import pandas as pd\n",
    "dir = \"E:/ChristianMusaeus/Data/Eyes_closed_marked\"\n",
    "with open(f\"{dir}/trimmed_open_data.pkl\", \"rb\") as f:\n",
    "    trimmed_open_data = pickle.load(f)\n",
    "\n",
    "with open(f\"{dir}/trimmed_closed_data.pkl\", \"rb\") as f:\n",
    "    trimmed_closed_data = pickle.load(f)\n",
    "\n",
    "\n",
    "# convert trimmed_closed_data to a dataframe\n",
    "closed_df = pd.DataFrame()\n",
    "for i, data in enumerate(trimmed_closed_data):\n",
    "    data = data.reshape(60, -1)\n",
    "    df = pd.DataFrame(data)\n",
    "    closed_df = pd.concat([closed_df, df], axis=0)\n",
    "closed_df[\"label\"] = 1\n",
    "\n",
    "open_df = pd.DataFrame()\n",
    "for i, data in enumerate(trimmed_open_data):\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    df = pd.DataFrame(data)\n",
    "    open_df = pd.concat([open_df, df], axis=0)\n",
    "open_df[\"label\"] = 0\n",
    "\n",
    "# stack the two dataframes vertically\n",
    "df = pd.concat([closed_df, open_df], axis=0)\n",
    "print(df.head(), df.shape)\n",
    "\n",
    "# save df as a pickle file\n",
    "with open(f\"{dir}/df_EOandEC.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Patient ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740 1475\n",
      "(3215, 3802)\n",
      "          0         1         2         3         4         5             6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.000010 -0.000014 -0.000020 -1.990352e-05   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.000020 -0.000026 -0.000026 -2.479350e-05   \n",
      "2  0.000022  0.000018  0.000013  0.000008  0.000003  0.000001  9.871100e-07   \n",
      "3  0.000007  0.000003 -0.000001 -0.000004 -0.000007 -0.000008 -6.191659e-06   \n",
      "4  0.000013  0.000013  0.000012  0.000012  0.000010  0.000010  1.009186e-05   \n",
      "\n",
      "              7         8             9  ...      3792          3793  \\\n",
      "0 -2.007265e-05 -0.000019 -1.404443e-05  ... -0.000010 -6.451550e-06   \n",
      "1 -2.346011e-05 -0.000018 -1.718349e-05  ...  0.000002  8.180189e-07   \n",
      "2 -2.112761e-07 -0.000002 -1.798665e-06  ... -0.000005 -1.266182e-07   \n",
      "3 -4.011699e-06 -0.000002  4.808684e-07  ... -0.000005 -4.692287e-06   \n",
      "4  8.046945e-06  0.000007  4.599984e-06  ...  0.000002  2.542886e-06   \n",
      "\n",
      "       3794      3795      3796      3797          3798      3799  label  \\\n",
      "0 -0.000002  0.000002  0.000005  0.000007  6.550796e-06  0.000006      1   \n",
      "1 -0.000004 -0.000009 -0.000012 -0.000012 -1.015951e-05 -0.000007      1   \n",
      "2  0.000004  0.000006  0.000008  0.000007  6.221105e-06  0.000005      1   \n",
      "3 -0.000005 -0.000004 -0.000003 -0.000002 -3.944589e-07  0.000002      1   \n",
      "4  0.000005  0.000008  0.000012  0.000015  1.492380e-05  0.000012      1   \n",
      "\n",
      "   patient_id  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "\n",
      "[5 rows x 3802 columns]\n"
     ]
    }
   ],
   "source": [
    "closed_patient_ids = np.repeat(np.arange(0, 29), 60)\n",
    "\n",
    "print(len(closed_patient_ids), len(open_patient_ids))\n",
    "patient_ids = np.concatenate([closed_patient_ids, open_patient_ids])\n",
    "\n",
    "# attach patient ids to df\n",
    "df[\"patient_id\"] = patient_ids\n",
    "print(df.shape)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data patientwise(global patient parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before scaling:           0         1         2        3         4         5         6  \\\n",
      "0 -0.000004 -0.000009 -0.000012 -0.00001 -0.000014 -0.000020 -0.000020   \n",
      "1 -0.000005 -0.000012 -0.000015 -0.00002 -0.000026 -0.000026 -0.000025   \n",
      "\n",
      "          7         8         9  ...      3792          3793      3794  \\\n",
      "0 -0.000020 -0.000019 -0.000014  ... -0.000010 -6.451550e-06 -0.000002   \n",
      "1 -0.000023 -0.000018 -0.000017  ...  0.000002  8.180189e-07 -0.000004   \n",
      "\n",
      "       3795      3796      3797      3798      3799  label  patient_id  \n",
      "0  0.000002  0.000005  0.000007  0.000007  0.000006      1           0  \n",
      "1 -0.000009 -0.000012 -0.000012 -0.000010 -0.000007      1           0  \n",
      "\n",
      "[2 rows x 3802 columns]\n",
      "after scaling: [[-0.22054073 -0.23624156 -0.17988051 ...  0.60395375  1.\n",
      "   0.        ]\n",
      " [-0.23374289 -0.28206085 -0.22675689 ... -0.11500413  1.\n",
      "   0.        ]]\n",
      "min and max: -1.0, 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "y = df[\"label\"].values\n",
    "patient_ids = df[\"patient_id\"].values\n",
    "\n",
    "# Normalize per patient (within training and test sets)\n",
    "print(f\"before scaling: {df.head(2)}\")\n",
    "df = df.drop(columns=[\"label\", \"patient_id\"])  # Drop the label and patient id columns\n",
    "df_norm = []\n",
    "for patient_id in np.unique(patient_ids):\n",
    "    patient_data = df[patient_ids == patient_id]\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    patient_data_scaled = scaler.fit_transform(patient_data)\n",
    "    df_norm.append(patient_data_scaled)\n",
    "\n",
    "df_norm = np.concatenate(df_norm, axis=0)\n",
    "# Add labels back\n",
    "df_norm = np.concatenate([df_norm, y.reshape(-1, 1)], axis=1)\n",
    "# Add patient ids back\n",
    "df_norm = np.concatenate([df_norm, patient_ids.reshape(-1, 1)], axis=1)\n",
    "print(f\"after scaling: {df_norm[:2]}\")\n",
    "print(f\"min and max: {np.min(df_norm)}, {np.max(df_norm[:, :-2])}\")\n",
    "\n",
    "# save df_norm as a pickle file\n",
    "with open(f\"{dir}/df_EOandEC_norm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_norm, f)\n",
    "\n",
    "# save in a differnt format also\n",
    "df = pd.DataFrame(df_norm)\n",
    "df.to_csv(f\"{dir}/df_EOandEC_norm.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: -1.0, max: 1.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check min and max values\n",
    "print(f\"min: {np.min(df_norm)}, max: {np.max(df_norm[:, :-2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of spectrograms: 3215\n",
      "3927\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.186564  0.475278  0.505854  0.306700  0.255097  0.557123  0.555072   \n",
      "1  0.131151  0.520671  0.447478  0.456006  0.052131  0.583297  0.527655   \n",
      "2  0.123682  0.148802  0.332623  0.198912  0.240235  0.298129  0.357936   \n",
      "3  0.168667  0.463728  0.337087  0.306425  0.304572  0.543767  0.367835   \n",
      "4  0.143401  0.420038  0.098637  0.138659  0.324467  0.524166  0.083871   \n",
      "\n",
      "          7         8         9  ...      3919      3920      3921      3922  \\\n",
      "0  0.407374  0.221913  0.021099  ...  0.001207  0.002463  0.000491  0.005581   \n",
      "1  0.536725  0.081143  0.052932  ...  0.002277  0.001954  0.001542  0.003579   \n",
      "2  0.325636  0.169057  0.191902  ...  0.002602  0.001009  0.000062  0.007482   \n",
      "3  0.455260  0.288131  0.157854  ...  0.001342  0.001138  0.001100  0.000432   \n",
      "4  0.324291  0.224512  0.130821  ...  0.001786  0.002207  0.000786  0.001823   \n",
      "\n",
      "       3923      3924      3925      3926  label  patient_id  \n",
      "0  0.001443  0.003982  0.002276  0.005611      1           0  \n",
      "1  0.000753  0.003467  0.003439  0.003056      1           0  \n",
      "2  0.000660  0.002182  0.002051  0.005261      1           0  \n",
      "3  0.001260  0.003974  0.003283  0.002847      1           0  \n",
      "4  0.000753  0.002303  0.003585  0.007058      1           0  \n",
      "\n",
      "[5 rows x 3929 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "\n",
    "reshaped_data = df_norm[:, :-2]\n",
    "\n",
    "fs = 200  # Sampling frequency (in Hz)\n",
    "nperseg = fs/2  # Length of each segment for STFT (typically a power of 2)\n",
    "\n",
    "# create empty list for the spectrograms, each channel will have its own list\n",
    "spectrograms = [[] for _ in range(reshaped_data.shape[0])]\n",
    "print(f\"shape of spectrograms: {len(spectrograms)}\")\n",
    "\n",
    "for i, epoch in enumerate(reshaped_data): # loop over datarows\n",
    "    frequencies, times, Zxx = stft(epoch, fs, nperseg=nperseg)\n",
    "    spectrogram = np.abs(Zxx)  # Shape: (n_freq_bins, n_time_segments)\n",
    "    # print(f\"shape of spectrogram: {spectrogram.shape}\")\n",
    "\n",
    "    # Flatten the spectrogram of this channel\n",
    "    spectrogram_flattened = spectrogram.flatten()  # Flatten to 1D array\n",
    "    \n",
    "    # Append to list\n",
    "    spectrograms[i] = spectrogram_flattened\n",
    "\n",
    "print(len(spectrograms[0]))\n",
    "\n",
    "# save spectrograms as a pickle file\n",
    "spectrograms = np.array(spectrograms)\n",
    "df = pd.DataFrame(spectrograms)\n",
    "df[\"label\"] = y\n",
    "df[\"patient_id\"] = patient_ids\n",
    "print(df.head())\n",
    "\n",
    "with open(f\"{dir}/hospital_spectrograms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(spectrograms, f)\n",
    "\n",
    "# save as a csv file\n",
    "df.to_csv(f\"{dir}/hospital_spectrograms.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Reg Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy for Patient 0: 90.29%\n",
      "Model accuracy for Patient 1: 99.43%\n",
      "Model accuracy for Patient 2: 100.00%\n",
      "Model accuracy for Patient 3: 98.12%\n",
      "Model accuracy for Patient 4: 100.00%\n",
      "Model accuracy for Patient 5: 97.26%\n",
      "Model accuracy for Patient 6: 100.00%\n",
      "Model accuracy for Patient 7: 97.95%\n",
      "Model accuracy for Patient 8: 100.00%\n",
      "Model accuracy for Patient 9: 98.70%\n",
      "Model accuracy for Patient 10: 99.07%\n",
      "Model accuracy for Patient 11: 96.70%\n",
      "Model accuracy for Patient 12: 100.00%\n",
      "Model accuracy for Patient 13: 99.03%\n",
      "Model accuracy for Patient 14: 100.00%\n",
      "Model accuracy for Patient 15: 100.00%\n",
      "Model accuracy for Patient 16: 96.39%\n",
      "Model accuracy for Patient 17: 100.00%\n",
      "Model accuracy for Patient 18: 100.00%\n",
      "Model accuracy for Patient 19: 99.36%\n",
      "Model accuracy for Patient 20: 98.10%\n",
      "Model accuracy for Patient 21: 98.94%\n",
      "Model accuracy for Patient 22: 99.09%\n",
      "Model accuracy for Patient 23: 100.00%\n",
      "Model accuracy for Patient 24: 100.00%\n",
      "Model accuracy for Patient 25: 99.19%\n",
      "Model accuracy for Patient 26: 98.48%\n",
      "Model accuracy for Patient 27: 100.00%\n",
      "Model accuracy for Patient 28: 69.77%\n",
      "Average accuracy across patients: 97.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "accs = []\n",
    "\n",
    "# Initialize Leave-One-Group-Out cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "patient_ids = df_norm[:, -1]\n",
    "y = df_norm[:, -2]\n",
    "data = df_norm[:, :-2]\n",
    "\n",
    "# Train-test split using Leave-One-Group-Out\n",
    "for i, (train_index, test_index) in enumerate(logo.split(data, y, groups=patient_ids)):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000, verbose=1,class_weight=\"balanced\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accs.append(accuracy)\n",
    "    print(f'Model accuracy for Patient {i}: {accuracy*100:.2f}%')\n",
    "\n",
    "# Print the average accuracy over all patients\n",
    "print(f'Average accuracy across patients: {np.mean(accs)*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".LogReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
