{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer on spectrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2980,) [1 1 0 0 0]\n",
      "(6175,)\n",
      "progress: 0/2980\n",
      "progress: 100/2980\n",
      "progress: 200/2980\n",
      "progress: 300/2980\n",
      "progress: 400/2980\n",
      "progress: 500/2980\n",
      "progress: 600/2980\n",
      "progress: 700/2980\n",
      "progress: 800/2980\n",
      "progress: 900/2980\n",
      "progress: 1000/2980\n",
      "progress: 1100/2980\n",
      "progress: 1200/2980\n",
      "progress: 1300/2980\n",
      "progress: 1400/2980\n",
      "progress: 1500/2980\n",
      "progress: 1600/2980\n",
      "progress: 1700/2980\n",
      "progress: 1800/2980\n",
      "progress: 1900/2980\n",
      "progress: 2000/2980\n",
      "progress: 2100/2980\n",
      "progress: 2200/2980\n",
      "progress: 2300/2980\n",
      "progress: 2400/2980\n",
      "progress: 2500/2980\n",
      "progress: 2600/2980\n",
      "progress: 2700/2980\n",
      "progress: 2800/2980\n",
      "progress: 2900/2980\n",
      "(2980, 6176)\n"
     ]
    }
   ],
   "source": [
    "# load the combined features from the pickle file\n",
    "import pickle\n",
    "dir = \"C:/Users/gusta/OneDrive/Skrivebord/KI & Data/Bachelor/LegeData\"\n",
    "with open(f\"{dir}/combined_stft_features_19.pkl\", \"rb\") as f:\n",
    "    combined_stft_features = pickle.load(f)\n",
    "    \n",
    "\n",
    "# # Assuming this corresponds to one label, e.g., `label`\n",
    "labels = []\n",
    "for _ in range(10):\n",
    "    labels.append(np.repeat([1,0],149))\n",
    "\n",
    "    \n",
    "y = np.array([labels]).flatten()\n",
    "print(y.shape, y[147:152])  # Should be (1, 2980)\n",
    "\n",
    "\n",
    "\n",
    "X = combined_stft_features\n",
    "train_sample = X[:,:325].flatten()\n",
    "print(train_sample.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare to create the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Loop through the number of segments in X\n",
    "num_segments = 2980\n",
    "num_features = 6175  # 19 channels * 325 features per channel\n",
    "# Step 1: Pre-allocate the array for the final data\n",
    "# Each row will have num_features features\n",
    "flattened_data = np.zeros((num_segments, num_features))\n",
    "\n",
    "# Step 2: Extract and flatten segments\n",
    "for i in range(num_segments):\n",
    "    if i % 100 == 0: \n",
    "        print(f\"progress: {i}/{num_segments}\")\n",
    "    # Extract the current block of 325 data points across 19 channels\n",
    "    segment_features = combined_stft_features[:, i * 325:(i * 325 + 325)]\n",
    "    \n",
    "    # Flatten the block to 1D and place it in the corresponding row\n",
    "    flattened_data[i, :] = segment_features.flatten()\n",
    "\n",
    "# Step 3: Create the DataFrame using the flattened data\n",
    "# Create the DataFrame directly from the pre-allocated NumPy array\n",
    "data = pd.DataFrame(flattened_data, columns=[f'feature_{j+1}' for j in range(num_features)])\n",
    "\n",
    "# Step 4: Add labels to the DataFrame\n",
    "data['label'] = y\n",
    "\n",
    "# Check the shape of the final DataFrame\n",
    "print(data.shape)  # Should be (2980, 6175 + 1)\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()\n",
    "\n",
    "patient_ids = np.repeat([1,2,3,4,5,6,7,8,9,10],298)  # Make sure to have this aligned with your epochs/labels\n",
    "\n",
    "# Normalize per patient (within training and test sets)\n",
    "data = data.iloc[:, :-1].values  # Drop the label column\n",
    "data_norm = []\n",
    "for patient_id in np.unique(patient_ids):\n",
    "    patient_data = data[patient_ids == patient_id]\n",
    "    scaler = StandardScaler()\n",
    "    patient_data_scaled = scaler.fit_transform(patient_data)\n",
    "    data_norm.append(patient_data_scaled)\n",
    "\n",
    "data_norm = np.concatenate(data_norm, axis=0)\n",
    "# add labels back\n",
    "data_norm = np.concatenate([data_norm, y.reshape(-1, 1)], axis=1)\n",
    "data = data_norm\n",
    "data.shape  # Should be (2980, 6175 + 1)\n",
    "\n",
    "# save as pickle\n",
    "with open(f\"{dir}/data_norm_19_spectrograms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# drop labels   \n",
    "labels = data[:, -1]\n",
    "data = data[:, :-1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochTransformer(nn.Module):\n",
    "    def __init__(self, n_positions, n_embedding, n_datapoints, num_heads, num_layers):\n",
    "        super(EpochTransformer, self).__init__()\n",
    "        self.L = 10000\n",
    "        self.n_positions = n_positions\n",
    "        self.n_embedding = n_embedding\n",
    "        self.n_datapoints = n_datapoints\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=self.n_embedding, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "\n",
    "    def positional_encoding(self, n_positions, n_datapoints, L=10000):\n",
    "        \"\"\"\n",
    "        Generates positional encodings directly to match the size of the data matrix.\n",
    "\n",
    "        Args:\n",
    "            n_positions (int): Number of positions (sequence length).\n",
    "            n_datapoints (int): Number of datapoints (embedding size per epoch).\n",
    "            L (int): Maximum sequence length (default 10000).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Positional encoding matrix of shape (n_positions, n_datapoints).\n",
    "        \"\"\"\n",
    "        n = torch.arange(n_positions)[:, None]  # (n_positions, 1)\n",
    "        i = torch.arange(n_datapoints)[None, :]  # (1, n_datapoints)\n",
    "\n",
    "        # Compute positional encodings using the vectorized formula\n",
    "        angle_rates = 1 / (L ** (i / n_datapoints))\n",
    "        angle_rads = n * angle_rates\n",
    "\n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        encoding = torch.zeros_like(angle_rads)\n",
    "        encoding[:, 0::2] = torch.sin(angle_rads[:, 0::2])\n",
    "        encoding[:, 1::2] = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        return encoding\n",
    "\n",
    "    def add_positional_encoding(self, data_matrix, L=10000):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the data matrix directly, matching the size of the matrix.\n",
    "\n",
    "        Args:\n",
    "            data_matrix (torch.Tensor): The data matrix of shape (batch_size, seq_len, n_datapoints).\n",
    "            L (int): Maximum sequence length (default 10000).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Data matrix with added positional encoding.\n",
    "        \"\"\"\n",
    "        # Extract the sequence length (seq_len) and embedding size (n_datapoints)\n",
    "        batch_size, n_positions, n_datapoints = data_matrix.shape  # Handle batch_size\n",
    "\n",
    "        # Generate positional encoding for the sequence length and embedding size\n",
    "        pos_enc = self.positional_encoding(n_positions, n_datapoints, L).to(data_matrix.device)\n",
    "        \n",
    "        # Add positional encoding to each sequence in the batch\n",
    "        pos_enc = pos_enc.unsqueeze(0).expand(batch_size, -1, -1)  # Expand to match batch size\n",
    "        \n",
    "        # Add the positional encoding to the data matrix\n",
    "        data_matrix_with_pos_enc = data_matrix + pos_enc\n",
    "        \n",
    "        return data_matrix_with_pos_enc\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.add_positional_encoding(x).float() # convert to float\n",
    "        output = self.transformer_encoder(x)\n",
    "        return output  # Compress into a feature vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len, embedding_dim, num_heads, num_layers):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "    \n",
    "    def add_sequence_positional_encoding(self, epoch_matrix, seq_len, embedding_dim):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the sequence of epochs.\n",
    "        Args:\n",
    "            epoch_matrix (torch.Tensor): The sequence of epoch feature vectors (batch_size, seq_len, embedding_dim)\n",
    "            seq_len (int): Length of the sequence (number of epochs).\n",
    "            embedding_dim (int): Embedding dimension per epoch.\n",
    "        Returns:\n",
    "            torch.Tensor: Sequence with added positional encoding.\n",
    "        \"\"\"\n",
    "        n = torch.arange(seq_len)[:, None]\n",
    "        i = torch.arange(embedding_dim)[None, :]\n",
    "        angle_rates = 1 / (10000 ** (i / embedding_dim))\n",
    "        pos_enc = torch.zeros((seq_len, embedding_dim))\n",
    "        pos_enc[:, 0::2] = torch.sin(n * angle_rates[:, 0::2])\n",
    "        pos_enc[:, 1::2] = torch.cos(n * angle_rates[:, 1::2])\n",
    "        \n",
    "        return epoch_matrix + pos_enc\n",
    "\n",
    "\n",
    "    def forward(self, epoch_output_seq):\n",
    "        # Add positional encoding to the sequence of epoch outputs\n",
    "        encoded_seq = self.add_sequence_positional_encoding(epoch_output_seq, self.seq_len, self.embedding_dim).float()\n",
    "        # Pass through the transformer encoder\n",
    "        output_seq = self.transformer_encoder(encoded_seq)\n",
    "        return output_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, n_positions, n_embedding, seq_len, num_heads, num_layers):\n",
    "        super(FinalModel, self).__init__()\n",
    "        # Initialize Epoch Transformer and Sequence Transformer\n",
    "        self.epoch_transformer = EpochTransformer(n_positions, n_embedding, n_embedding, num_heads, num_layers)\n",
    "        self.sequence_transformer = SequenceTransformer(seq_len, n_embedding, num_heads, num_layers)\n",
    "        # Fully connected layers for final classification\n",
    "        self.fc1 = nn.Linear(n_embedding, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x, target_idx):\n",
    "        \"\"\"\n",
    "        Forward pass for the model.\n",
    "        Args:\n",
    "            x: Input of shape (batch_size, seq_len, n_datapoints)\n",
    "            target_idx: The index of the target epoch to classify.\n",
    "        \"\"\"\n",
    "        # Process the batch of epochs through the Epoch Transformer\n",
    "        batch_size, seq_len, n_datapoints = x.shape\n",
    "        \n",
    "        # Pass all epochs in the sequence through the Epoch Transformer\n",
    "        epoch_outputs = self.epoch_transformer(x)  # Shape: [batch_size, seq_len, n_embedding]\n",
    "        \n",
    "        # Process the entire sequence of epochs through the Sequence Transformer\n",
    "        sequence_output = self.sequence_transformer(epoch_outputs)  # Shape: [batch_size, seq_len, n_embedding]\n",
    "        \n",
    "        # Extract the specific epoch representation (e.g., epoch 6) from the sequence\n",
    "        target_epoch_output = sequence_output[:, target_idx]  # Shape: [batch_size, n_embedding]\n",
    "        \n",
    "        # Pass the target epoch's output through fully connected layers for classification\n",
    "        out = F.relu(self.fc1(target_epoch_output))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return F.softmax(out, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\miniconda3\\envs\\BACHELOR\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalModel(\n",
      "  (epoch_transformer): EpochTransformer(\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6175, out_features=6175, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=6175, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=6175, bias=True)\n",
      "          (norm1): LayerNorm((6175,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((6175,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sequence_transformer): SequenceTransformer(\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=6175, out_features=6175, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=6175, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=6175, bias=True)\n",
      "          (norm1): LayerNorm((6175,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((6175,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=6175, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FinalModel(n_positions=2980, n_embedding=6175, seq_len=11, num_heads=5, num_layers=3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\miniconda3\\envs\\BACHELOR\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch of 10 sequences, each with 11 epochs and 6175 features\n",
    "batch_size = 5\n",
    "seq_len = 11  # We use 11 epochs in total (5 before, 1 target, 5 after)\n",
    "n_datapoints = 6175\n",
    "\n",
    "# Initialize the model\n",
    "model = FinalModel(n_positions=2980, n_embedding=6175, seq_len=seq_len, num_heads=5, num_layers=3)\n",
    "\n",
    "# Random input tensor of shape [batch_size, seq_len, n_datapoints]\n",
    "x = torch.randn(batch_size, seq_len, n_datapoints)\n",
    "\n",
    "# We want to classify epoch 6 \n",
    "target_idx = 5\n",
    "\n",
    "# Forward pass\n",
    "output = model(x, target_idx)\n",
    "print(output.shape)  # Should be [batch_size, 2] for binary classification\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BACHELOR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
